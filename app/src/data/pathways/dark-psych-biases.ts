import type { PathwayLesson } from '@/types';

export const cognitiveBiasLessons: PathwayLesson[] = [
  {
    id: 'dp-bias-001',
    title: 'What Are Cognitive Biases - Overview',
    type: 'concept',
    duration: 12,
    xpReward: 100,
    content: {
      overview: 'Understanding the mental shortcuts that shape our decisions and make us vulnerable to manipulation.',
      mainContent: `**The Hidden Programming of Your Mind**

Cognitive biases are systematic patterns of deviation from rational judgment. They are mental shortcuts—called heuristics—that our brains developed to make quick decisions in a complex world. While these shortcuts often serve us well, they also create predictable blind spots that manipulators can exploit.

**Why Biases Exist**

Our ancestors didn't have time to carefully analyze whether that rustling in the bushes was a predator or just the wind. Those who assumed danger and acted quickly survived. Those who deliberated often didn't. This evolutionary pressure shaped brains that prioritize speed over accuracy in many situations.

Today, we inherit these same mental shortcuts, but we face a very different environment. Instead of saber-toothed tigers, we face salespeople, politicians, con artists, and algorithms—all designed to exploit our cognitive vulnerabilities.

**The Scope of the Problem**

Researchers have identified over 180 distinct cognitive biases. They affect every domain of human decision-making:

- **Perception**: What we notice and ignore
- **Memory**: What we remember and forget
- **Judgment**: How we evaluate options
- **Social interaction**: How we interpret others' behavior
- **Self-assessment**: How we view our own abilities

**The Exploitation Opportunity**

What makes biases dangerous isn't just that we have them—it's that they're predictable. A skilled manipulator doesn't need to understand you personally. They only need to understand human psychology generally. Your biases follow patterns that have been studied, documented, and weaponized.

**The Defense Begins with Awareness**

The good news: biases operate most powerfully when we're unaware of them. Simply knowing a bias exists reduces its influence. Throughout this module, you'll learn to:

1. Identify the most exploitable biases
2. Recognize when they're being triggered
3. Implement practical countermeasures
4. Build habits that protect your decision-making

Think of this knowledge as installing antivirus software for your mind. You can't eliminate biases—they're hardwired—but you can learn to catch them before they compromise your judgment.`,
      keyTakeaway: 'Cognitive biases are predictable mental shortcuts that manipulators exploit. Awareness is your first line of defense.',
      actionItem: 'For the next 24 hours, notice moments when you make quick judgments. Ask yourself: "What mental shortcut am I using right now?"',
    },
  },
  {
    id: 'dp-bias-002',
    title: 'Confirmation Bias - Seeing What We Believe',
    type: 'concept',
    duration: 14,
    xpReward: 110,
    content: {
      overview: 'How our tendency to seek confirming evidence makes us vulnerable to manipulation.',
      mainContent: `**The Mind's Yes-Man**

Confirmation bias is the tendency to search for, interpret, favor, and recall information that confirms our existing beliefs while giving disproportionately less attention to information that contradicts them. It's not that we can't see contrary evidence—we just don't look for it, and when we find it, we scrutinize it far more harshly.

**How It Works**

Imagine you believe a certain politician is corrupt. You'll notice every scandal, remember every questionable decision, and interpret ambiguous actions as suspicious. Meanwhile, evidence of their integrity barely registers. You're not lying to yourself—your brain is genuinely filtering reality to match your expectations.

This happens through three mechanisms:

1. **Selective exposure**: We choose information sources that agree with us
2. **Selective perception**: We interpret ambiguous information to fit our views
3. **Selective recall**: We remember confirming evidence more easily

**Exploitation Tactics**

Manipulators weaponize confirmation bias by:

- **Identifying your existing beliefs** and framing their pitch to align with them
- **Feeding you "evidence"** that confirms what you already suspect
- **Creating echo chambers** where you only hear agreeing voices
- **Using leading questions** that prime you to confirm their narrative

A con artist doesn't try to change your mind—they figure out what you already believe and use it against you. If you distrust banks, they'll pitch an "alternative investment." If you believe you're smarter than average, they'll present an "exclusive opportunity most people can't understand."

**Defense Strategies**

1. **Actively seek disconfirmation**: Before making important decisions, deliberately look for evidence against your position
2. **Steel-man opposing views**: Argue the strongest version of the opposing case, not the weakest
3. **Consider the source**: Ask whether you're accepting this information because it's credible or because it's comfortable
4. **Use the "outsider test"**: How would someone with the opposite belief interpret this same evidence?

**The Intellectual Humility Check**

Ask yourself: "What would change my mind?" If you can't answer that question, you're not reasoning—you're rationalizing. And that's exactly the state manipulators want you in.`,
      keyTakeaway: 'Confirmation bias makes us seek evidence that supports what we already believe. Manipulators exploit this by aligning their pitch with your existing worldview.',
      actionItem: 'Identify one strongly held belief. Spend 15 minutes actively searching for the best arguments against it. Notice how uncomfortable this feels.',
    },
  },
  {
    id: 'dp-bias-003',
    title: 'Anchoring Effect - First Impressions Matter',
    type: 'concept',
    duration: 12,
    xpReward: 110,
    content: {
      overview: 'Understanding how initial information disproportionately influences all subsequent judgments.',
      mainContent: `**The Number That Controls You**

The anchoring effect describes our tendency to rely too heavily on the first piece of information we receive (the "anchor") when making decisions. Even when the anchor is arbitrary or irrelevant, it pulls our subsequent estimates toward it.

**The Classic Experiment**

Researchers asked people to spin a wheel that landed on either 10 or 65, then estimate what percentage of African countries are in the United Nations. Those who saw 10 guessed around 25%. Those who saw 65 guessed around 45%. A random number from a wheel—completely unrelated to the question—shifted estimates by 20 percentage points.

**Why It's So Powerful**

Anchoring works because our brains use the anchor as a starting point and then adjust—but we adjust insufficiently. We don't have unlimited mental energy to evaluate every piece of information from scratch, so we take shortcuts. The anchor provides a reference point, and we move from there rather than calculating independently.

**Exploitation in Action**

Manipulators use anchoring constantly:

- **Pricing**: The "original price" of $500 makes the "sale price" of $200 seem like a bargain, even if the item was never worth $500
- **Negotiations**: The first number mentioned shapes the entire negotiation range
- **Statistics**: "9 out of 10 dentists recommend..." anchors you to think the product is nearly universal
- **Time pressure**: "This offer expires in 24 hours" anchors urgency before you can evaluate fairly
- **Comparisons**: Showing you an expensive option first makes the medium option seem reasonable

**Defense Strategies**

1. **Recognize the anchor**: When someone gives you a number first, ask yourself why they chose that specific number
2. **Generate your own anchor**: Before receiving their information, form your own independent estimate
3. **Consider the opposite extreme**: If they anchor high, deliberately consider unrealistically low values to counterbalance
4. **Delay response**: Anchoring is strongest when you respond immediately; taking time weakens its grip
5. **Seek multiple reference points**: Don't rely on a single data point; gather several independent sources

**The Counter-Anchor Technique**

When negotiating, always establish your own anchor first if possible. If they anchor first, explicitly reject the anchor: "That number doesn't reflect the market. Let's start from actual comparable sales." Naming the tactic reduces its power.`,
      keyTakeaway: 'The first number you hear disproportionately influences your judgment. Manipulators set anchors strategically to control your perception of value.',
      actionItem: 'Next time you see a "sale" price, ignore the original price entirely. Research what comparable items actually sell for before deciding if it is a good deal.',
    },
  },
  {
    id: 'dp-bias-004',
    title: 'Availability Heuristic - Recent = Important',
    type: 'concept',
    duration: 13,
    xpReward: 110,
    content: {
      overview: 'How easily recalled information distorts our perception of probability and risk.',
      mainContent: `**The Memory Distortion**

The availability heuristic is our tendency to judge the likelihood of events based on how easily examples come to mind. If something is easy to remember—because it's recent, vivid, or emotionally charged—we assume it's more common or more likely than it actually is.

**How It Misleads Us**

After watching news coverage of a plane crash, people overestimate the danger of flying, even though statistically, the drive to the airport is far more dangerous. The crash is vivid and recent; the thousands of safe flights are invisible.

This isn't stupidity—it's a reasonable shortcut that usually works. Things that happen frequently are generally easier to recall. The problem is that memorability is influenced by many factors besides actual frequency:

- **Recency**: Recent events feel more likely
- **Vividness**: Dramatic events stick in memory
- **Emotional impact**: Scary or exciting events are more memorable
- **Media coverage**: Reported events seem more common
- **Personal experience**: What happened to you feels more probable

**Exploitation Tactics**

Manipulators exploit availability by:

- **Creating vivid scenarios**: "Imagine losing everything you've worked for..." makes unlikely disasters feel imminent
- **Citing memorable examples**: One dramatic story outweighs statistics
- **Timing their pitch**: After a relevant news event, related fears are elevated
- **Using testimonials**: Personal stories are more available than data
- **Repetition**: Saying something repeatedly makes it feel more true and common

Fear-based manipulation almost always leverages availability. Terrorists, politicians, and salespeople all understand that one dramatic image is worth a thousand statistics.

**Defense Strategies**

1. **Ask for base rates**: "How often does this actually happen?" Force yourself to look up statistics rather than relying on memory
2. **Consider what's missing**: What events would be equally dramatic but don't get coverage? What about all the non-events?
3. **Recognize emotional loading**: The more emotional your reaction, the more suspicious you should be of your probability estimates
4. **Use time distance**: Ask yourself how worried you'd be about this in a year. Temporal distance reduces availability's distortion
5. **Seek boring data**: Deliberately look for dry, statistical information that doesn't rely on vivid examples

**The Invisibility Problem**

The most dangerous aspect of availability bias is that non-events are invisible. You never see headlines about "Millions of flights landed safely today" or "Nothing bad happened to most people." Manipulators exploit this asymmetry constantly.`,
      keyTakeaway: 'We judge probability by how easily we can recall examples. Manipulators create vivid, emotional scenarios to make unlikely events feel imminent.',
      actionItem: 'The next time you feel afraid of something, look up the actual statistical probability. Compare it to everyday risks you accept without worry.',
    },
  },
  {
    id: 'dp-bias-005',
    title: 'Sunk Cost Fallacy - Throwing Good After Bad',
    type: 'concept',
    duration: 14,
    xpReward: 120,
    content: {
      overview: 'Why we irrationally continue failing courses of action because of past investments.',
      mainContent: `**The Trap of Past Investment**

The sunk cost fallacy is the tendency to continue investing in something because of previously invested resources (time, money, effort), even when continuing is not the best decision. Rationally, past costs that cannot be recovered should not influence future decisions—but they do.

**The Psychology Behind It**

We fall for sunk costs because:

- **Loss aversion**: We hate "wasting" what we've already spent
- **Consistency drive**: We want our past decisions to be justified
- **Optimism bias**: We believe more investment will finally pay off
- **Ego protection**: Quitting feels like admitting failure

The classic example: You buy a non-refundable concert ticket, but on the night of the show, you feel sick. Rationally, the ticket money is gone either way—you should stay home. But most people force themselves to go, trying to "get their money's worth," even though they'll have a miserable time.

**Exploitation in Action**

Manipulators weaponize sunk costs by:

- **Getting small initial commitments**: Once you've invested anything, you're more likely to continue
- **Escalating gradually**: Each small additional investment seems reasonable given what you've already committed
- **Reminding you of past investments**: "After everything you've put into this, you can't quit now"
- **Creating switching costs**: Making it painful to leave locks you in
- **Framing quitting as failure**: "Only losers give up"

This is why scams often ask for small amounts first, then escalate. Cults demand increasing commitment. Abusive relationships gradually intensify. By the time you realize the magnitude of the problem, you've invested so much that leaving feels impossible.

**Defense Strategies**

1. **Apply the "fresh start" test**: If you were starting today with no prior investment, would you begin this course of action?
2. **Focus on future value only**: Past costs are irrelevant to future decisions. Ask only: "What will I gain vs. lose from this point forward?"
3. **Set kill criteria in advance**: Before starting any venture, define conditions under which you'll quit, regardless of investment
4. **Calculate the true cost of continuing**: The real cost isn't what you've spent—it's what you'll spend if you continue
5. **Separate ego from decisions**: Making a past mistake doesn't make you stupid; refusing to correct it does

**The Escape Question**

When you feel trapped by past investment, ask: "If a stranger handed me this situation right now—with no history—what would I do?" That's your answer. The past cannot be changed; only the future is within your control.`,
      keyTakeaway: 'We irrationally continue bad investments because quitting feels like wasting past efforts. Manipulators exploit this by gradually escalating your commitment.',
      actionItem: 'Identify something you are continuing only because of past investment. Apply the "fresh start" test and consider whether you should actually stop.',
    },
  },
  {
    id: 'dp-bias-006',
    title: 'Bandwagon Effect - Following the Crowd',
    type: 'concept',
    duration: 13,
    xpReward: 110,
    content: {
      overview: 'How social proof hijacks our judgment and makes us vulnerable to manufactured consensus.',
      mainContent: `**The Power of Social Proof**

The bandwagon effect is our tendency to adopt beliefs, ideas, or behaviors because many other people do the same. When uncertain, we look to others for guidance—and often follow the crowd even when the crowd is wrong.

**Why We Conform**

Social proof served our ancestors well. In unfamiliar situations, copying successful group members was often the best strategy. If everyone runs, there's probably a predator. If everyone eats those berries, they're probably safe.

This instinct remains powerful because:

- **Information**: Others may know something we don't
- **Belonging**: We want to fit in with our group
- **Effort**: Independent research requires work; following is easy
- **Safety**: There's comfort in numbers

**The Asch Conformity Experiments**

In famous studies, participants were asked to judge which line matched a reference line—an obviously easy task. But when confederates unanimously gave wrong answers, 75% of participants conformed at least once, publicly agreeing with answers they knew were incorrect.

**Exploitation Tactics**

Manipulators manufacture social proof constantly:

- **Fake reviews and testimonials**: Creating the illusion of widespread approval
- **Astroturfing**: Making manufactured movements appear grassroots
- **Inflated numbers**: "Join millions of satisfied customers" (verified how?)
- **Selective showcasing**: Showing only supporters, hiding dissenters
- **Creating urgency through others**: "Everyone's buying this—don't miss out"
- **Laugh tracks and applause signs**: Telling you when to find something funny or impressive

Social media amplifies this massively. Bots, fake accounts, and coordinated campaigns create artificial consensus. You're shown what "everyone" thinks—but "everyone" might be a handful of accounts with an agenda.

**Defense Strategies**

1. **Verify the crowd**: Who are these "many people"? How do you know they exist and actually hold these views?
2. **Consider selection bias**: Are you seeing a representative sample or a curated echo chamber?
3. **Seek dissenting views**: Actively look for people who disagree. Why do they disagree?
4. **Use the "first person" test**: What would you think if you had to decide with zero knowledge of others' opinions?
5. **Remember Asch**: People will conform to obviously wrong answers. Popularity doesn't equal truth

**The Independence Practice**

Regularly practice forming opinions before checking what others think. Read articles before reading comments. Evaluate products before checking reviews. This builds the mental muscle of independent judgment.`,
      keyTakeaway: 'We follow the crowd, especially when uncertain. Manipulators manufacture fake consensus to trigger this instinct and guide your choices.',
      actionItem: 'Before your next purchase, form your own opinion of the product first. Then read reviews and notice how they influence or challenge your initial assessment.',
    },
  },
  {
    id: 'dp-bias-007',
    title: 'Halo Effect - Beautiful = Good',
    type: 'concept',
    duration: 12,
    xpReward: 110,
    content: {
      overview: 'How one positive trait creates an unearned glow that colors our entire perception of a person.',
      mainContent: `**The Radiant Illusion**

The halo effect is our tendency to let one positive trait influence our overall impression of a person. If someone is attractive, we unconsciously assume they're also intelligent, trustworthy, competent, and kind—with no evidence for any of these assumptions.

**How the Halo Works**

The effect operates across many traits:

- **Physical attractiveness** creates assumptions of intelligence and moral character
- **Confidence** suggests competence, even without demonstrated skill
- **Wealth** implies success through merit
- **Celebrity** transfers credibility to unrelated domains
- **Professional title** extends expertise beyond actual knowledge
- **Likability** generates trust, regardless of trustworthiness

The reverse also exists: the "horns effect" makes us judge people with one negative trait more harshly across all dimensions.

**The Research**

Studies show attractive defendants receive lighter sentences. Good-looking students get higher grades. Tall people earn more money. Confident speakers are rated as more knowledgeable, even when saying nothing of substance. These effects are unconscious and affect even those who know about them.

**Exploitation Tactics**

Manipulators leverage the halo effect by:

- **Investing heavily in appearance**: Looking successful to be treated as successful
- **Leading with strengths**: Showcasing one impressive trait to color your perception of everything else
- **Using attractive spokespeople**: Beautiful people selling products they know nothing about
- **Borrowing credibility**: Using titles, affiliations, or endorsements to create false expertise
- **Manufactured confidence**: Projecting certainty to be perceived as competent
- **Strategic name-dropping**: Associating with respected figures to absorb their glow

Con artists almost always present well. They understand that appearance is credibility in most people's minds.

**Defense Strategies**

1. **Separate traits deliberately**: Ask specifically—what evidence do I have for their competence? For their honesty? Don't let one answer bleed into another
2. **Beware of charm**: The more charming someone is, the more carefully you should verify their claims
3. **Judge by outcomes, not presentation**: What have they actually accomplished? What do their results show?
4. **Seek independent verification**: Don't take their word for credentials—check them
5. **Notice your emotional response**: If you're feeling impressed, that's exactly when you should slow down and think critically

**The Substance Test**

Ask yourself: "If this person were unattractive, uncharismatic, and unknown—would I still find their argument compelling?" If not, you're being influenced by the halo, not by evidence.`,
      keyTakeaway: 'One positive trait (especially attractiveness or confidence) makes us assume many other positive traits. Manipulators invest in appearance to exploit this shortcut.',
      actionItem: 'Think of someone you find impressive. List specifically what evidence you have for each positive trait you attribute to them. Notice where assumptions crept in.',
    },
  },
  {
    id: 'dp-bias-008',
    title: 'Dunning-Kruger Effect - Confidence vs Competence',
    type: 'concept',
    duration: 14,
    xpReward: 120,
    content: {
      overview: 'Understanding why the least competent are often the most confident, and how this creates exploitation opportunities.',
      mainContent: `**The Confidence-Competence Mismatch**

The Dunning-Kruger effect describes the cognitive bias where people with limited knowledge or competence in a domain greatly overestimate their own abilities, while true experts tend to underestimate theirs.

**Why It Happens**

The skills needed to produce correct responses are the same skills needed to recognize correct responses. If you lack expertise in a domain, you also lack the ability to recognize your own errors. You don't know what you don't know.

Meanwhile, experts are aware of the vast complexity in their field. They know how much they don't know, which makes them appropriately humble. The beginner sees a simple landscape; the expert sees an infinite horizon.

**The Confidence Curve**

Competence and confidence follow a predictable pattern:

1. **Unconscious incompetence**: You don't know anything, but you don't know that you don't know (high confidence)
2. **Conscious incompetence**: You learn enough to realize how much you don't know (confidence crashes)
3. **Conscious competence**: You develop real skill but remain aware of limitations (moderate confidence)
4. **Unconscious competence**: Mastery becomes natural, but you understand the field's depth (appropriately calibrated confidence)

**Exploitation Dynamics**

This effect creates two exploitation pathways:

**Exploiting the overconfident**: People at stage 1 are easy targets. They believe they understand things they don't, making them susceptible to:
- Fake expertise that confirms their existing (wrong) beliefs
- "Advanced" opportunities that flatter their self-image
- Scams that seem transparent to actual experts

**Using overconfidence to manipulate**: Manipulators exploit the effect by:
- Projecting supreme confidence to appear competent
- Using jargon and complexity to overwhelm genuinely knowledgeable skeptics
- Targeting domains where the victim has limited knowledge but doesn't realize it
- Making simple things sound complex (and vice versa) to confuse assessment

**Defense Strategies**

1. **Calibrate your confidence**: In areas where you feel very confident but have limited experience, increase skepticism
2. **Seek expert opinion**: True experts can assess claims you cannot. Find genuinely credible sources
3. **Beware of certainty**: Anyone expressing absolute certainty about complex topics is likely demonstrating the effect
4. **Test your knowledge**: Try to explain something simply. If you can't, you may understand less than you think
5. **Welcome being wrong**: Changing your mind when presented with evidence is a sign of intelligence, not weakness

**The Expertise Paradox**

The most confident voice in the room is often the least informed. True expertise typically comes with nuance, qualification, and acknowledgment of uncertainty. When someone speaks in absolutes about complex topics, that's a red flag, not a credential.`,
      keyTakeaway: 'The least competent often display the most confidence because they cannot recognize their own errors. Manipulators project false certainty to appear credible.',
      actionItem: 'Identify a topic where you feel confident but have limited formal training. Research it deeply for an hour and notice how your confidence changes.',
    },
  },
  {
    id: 'dp-bias-009',
    title: 'Loss Aversion - Pain of Losing vs Joy of Gaining',
    type: 'concept',
    duration: 13,
    xpReward: 120,
    content: {
      overview: 'Why losses hurt twice as much as equivalent gains feel good, and how this asymmetry is exploited.',
      mainContent: `**The Asymmetry of Pain and Pleasure**

Loss aversion refers to our tendency to prefer avoiding losses over acquiring equivalent gains. Research suggests losses feel approximately twice as powerful as gains—losing $100 hurts about twice as much as finding $100 feels good.

**The Evolutionary Logic**

This asymmetry makes evolutionary sense. For our ancestors, losing resources could mean death, while gaining extra resources had diminishing returns. A caveman who lost his only food source died; one who found extra food just got slightly less hungry. The stakes were asymmetric, so our emotional responses evolved to be asymmetric too.

**How Loss Aversion Manifests**

- We hold losing investments too long, hoping to avoid "realizing" the loss
- We overvalue things simply because we own them (endowment effect)
- We prefer the status quo, even when change would benefit us
- We take greater risks to avoid losses than to achieve gains
- We feel worse about losing something than we would feel good about gaining it

**Exploitation Tactics**

Manipulators weaponize loss aversion through:

- **Artificial scarcity**: "Only 3 left in stock!" creates fear of missing out
- **Limited time offers**: "Offer expires at midnight" triggers fear of loss
- **Free trials**: Once you have something, taking it away feels like a loss
- **Negative framing**: "You're losing $50 a day by not using our service" hits harder than "gain $50 a day"
- **Threatened removal**: "Your benefits will be discontinued unless..."
- **Sunk cost amplification**: Reminding you of what you'll "lose" if you quit

Fear-based marketing is almost always exploiting loss aversion. "Protect your family from..." is more effective than "Benefit your family with..." even when describing the identical outcome.

**Defense Strategies**

1. **Reframe losses as gains**: "What will I gain by letting this go?" instead of "What will I lose?"
2. **Use the symmetry test**: Would you pay the same amount to acquire this that you'd demand to give it up? If not, loss aversion is distorting your valuation
3. **Pre-commit to criteria**: Decide in advance when you'll sell investments, end subscriptions, or quit projects—before losses accumulate
4. **Recognize scarcity triggers**: When you feel urgency, pause. Artificial scarcity is designed to bypass rational evaluation
5. **Calculate opportunity costs**: What you keep prevents you from gaining something else. The "loss" of the status quo is often invisible

**The Inversion Question**

When facing a decision, ask: "If I didn't currently have this, would I pay/work to acquire it?" If no, you're holding on due to loss aversion, not actual value.`,
      keyTakeaway: 'Losses hurt about twice as much as equivalent gains feel good. Manipulators exploit this by framing everything as potential loss rather than potential gain.',
      actionItem: 'Notice the next advertisement that uses fear or loss framing. Reframe the message in terms of gain and observe how differently it feels.',
    },
  },
  {
    id: 'dp-bias-010',
    title: 'Framing Effect - How Presentation Changes Perception',
    type: 'concept',
    duration: 14,
    xpReward: 120,
    content: {
      overview: 'Understanding how the same information, presented differently, leads to opposite decisions.',
      mainContent: `**The Power of Presentation**

The framing effect demonstrates that people react differently to identical information depending on how it's presented. A medical procedure with a "90% survival rate" sounds safer than one with a "10% mortality rate"—yet they describe the exact same outcome.

**Why Framing Works**

Our brains don't process raw information objectively. We process it through the context in which it's presented. Framing effects occur because:

- We use mental shortcuts that are sensitive to presentation
- Positive and negative frames activate different emotional responses
- We don't naturally translate between equivalent descriptions
- First impressions (set by the frame) anchor subsequent processing

**Types of Frames**

**Gain vs. Loss Frames**: "Save $200" vs. "Don't lose $200"
**Positive vs. Negative**: "95% fat-free" vs. "5% fat"
**Absolute vs. Relative**: "Saves 100 lives" vs. "Reduces deaths by 50%"
**Individual vs. Statistical**: "John lost his home" vs. "1,000 foreclosures occurred"
**Temporal**: "Small daily payment" vs. "Large annual cost"

**Exploitation Tactics**

Manipulators are masters of strategic framing:

- **Selective statistics**: Choosing whichever number sounds better (relative vs. absolute, whatever favors their case)
- **Euphemism and dysphemism**: "Revenue enhancement" vs. "tax increase" for the same policy
- **Vivid vs. abstract**: Using emotional stories when statistics hurt their case, and vice versa
- **Temporal manipulation**: "Just $1 a day" instead of "$365 per year"
- **Comparison rigging**: Comparing their product to the worst competitor, not the best
- **Question framing**: The way a question is asked predetermines many answers

Political campaigns, advertising, and propaganda all rely heavily on strategic framing. The same policy can sound like salvation or catastrophe depending on presentation.

**Defense Strategies**

1. **Translate frames**: When presented with one frame, actively convert to the opposite. "90% survival" → "10% death"—does your feeling change?
2. **Demand multiple presentations**: Ask for the same information in different formats. Percentages AND absolute numbers. Annual AND daily costs
3. **Look for missing frames**: What perspective isn't being shown? Why might that be?
4. **Use neutral language**: When evaluating something important, strip away loaded language and describe it in plain terms
5. **Consider the framer's motive**: Why did they choose this particular presentation? What does it accomplish for them?

**The Translation Exercise**

Whenever you encounter a persuasive statistic or claim, force yourself to express it at least two other ways. This simple practice reveals how much of your reaction was to the frame rather than the underlying reality.`,
      keyTakeaway: 'Identical information presented differently leads to different decisions. Manipulators carefully choose frames that serve their agenda.',
      actionItem: 'Find a news article about a controversial topic. Identify the frames being used and rewrite key claims using opposite frames. Notice how your perception shifts.',
    },
  },
  {
    id: 'dp-bias-011',
    title: 'How Manipulators Exploit Biases',
    type: 'concept',
    duration: 15,
    xpReward: 130,
    content: {
      overview: 'Understanding the systematic methods manipulators use to identify and exploit cognitive vulnerabilities.',
      mainContent: `**The Manipulation Playbook**

Skilled manipulators don't rely on single techniques—they combine multiple bias exploits into sophisticated influence campaigns. Understanding their systematic approach helps you recognize and resist manipulation in all its forms.

**The Assessment Phase**

Before exploitation begins, manipulators gather intelligence:

- **What do you believe?** (to exploit confirmation bias)
- **What have you invested?** (to exploit sunk costs)
- **What do you fear losing?** (to exploit loss aversion)
- **Who do you trust?** (to exploit social proof)
- **What are you uncertain about?** (to exploit confidence gaps)

This can happen through casual conversation, social media analysis, or systematic profiling. The goal is to map your psychological vulnerabilities.

**The Combination Attack**

Sophisticated manipulation layers multiple biases simultaneously:

**Example: Investment Scam**
1. **Anchoring**: "Similar investments returned 400%"
2. **Social proof**: "Thousands of investors already joined"
3. **Scarcity**: "Only accepting 50 more investors this month"
4. **Authority/Halo**: Well-dressed presenter with impressive credentials
5. **Confirmation bias**: Targets people who already believe traditional investments are rigged
6. **Loss aversion**: "Don't miss this opportunity while others profit"
7. **Sunk cost**: Small initial investment, then escalating requests

Each layer reinforces the others, creating a web of influence that's harder to escape than any single technique.

**Common Combination Patterns**

**The Urgency Play**: Scarcity + Loss Aversion + Anchoring
"The price was $500, it's $200 today only, and there are only 3 left!"

**The Social Cascade**: Bandwagon + Authority + Halo Effect
"Expert-recommended, celebrity-endorsed, everyone's talking about it!"

**The Commitment Escalator**: Foot-in-door + Sunk Cost + Consistency
Small favors leading to large requests, with past compliance used as pressure.

**The Fear Complex**: Availability + Loss Aversion + Negative Framing
"Look at these horror stories of people who didn't act—don't let this happen to you!"

**Defense Architecture**

1. **Pattern recognition**: Learn to identify when multiple biases are being triggered simultaneously—that's a red flag
2. **Slow down deliberately**: Manipulation depends on fast, emotional decision-making. Time is your ally
3. **Separate the elements**: Break the pitch into components. Evaluate each claim independently
4. **Reverse-engineer the tactics**: Ask "What biases is this designed to trigger?"
5. **Consult unaffected parties**: Someone not exposed to the manipulation can think more clearly
6. **Use the "cold email" test**: Would you respond to this if it came from a stranger with no buildup?

**The Manipulation Audit**

Before any significant decision, run through the major biases: Am I being anchored? Is there artificial scarcity? Am I following a crowd? What have I already invested? What am I afraid of losing? This systematic check catches what intuition misses.`,
      keyTakeaway: 'Skilled manipulators combine multiple bias exploits simultaneously. Recognizing the pattern of layered manipulation is key to defense.',
      actionItem: 'Recall a time you were persuaded to do something you later regretted. Analyze it for bias combinations. How many different biases were being exploited?',
    },
  },
  {
    id: 'dp-bias-012',
    title: 'Recognizing When Biases Are Being Triggered',
    type: 'concept',
    duration: 14,
    xpReward: 130,
    content: {
      overview: 'Developing real-time awareness of your own cognitive vulnerabilities as they are exploited.',
      mainContent: `**The Early Warning System**

Knowing about biases intellectually is different from catching them in action. This lesson focuses on developing real-time recognition—the ability to notice when your biases are being activated before they compromise your judgment.

**Physical and Emotional Signals**

Your body often detects manipulation before your conscious mind does. Learn to recognize:

**Urgency signals**: Racing heart, feeling rushed, anxiety about missing out
- Likely bias: Scarcity, loss aversion
- Pause trigger: "Why do I feel I must decide RIGHT NOW?"

**Excitement spikes**: Sudden enthusiasm, feeling "lucky" or "chosen"
- Likely bias: Halo effect, social proof, flattery
- Pause trigger: "What specifically earned this emotional response?"

**Defensive reactions**: Anger at questions, dismissing skeptics
- Likely bias: Confirmation bias, commitment consistency
- Pause trigger: "Why am I defending this so strongly?"

**Overwhelm**: Feeling confused but trusting the presenter
- Likely bias: Authority, complexity exploitation
- Pause trigger: "Do I actually understand this, or am I just trusting?"

**Environmental Triggers**

Learn to recognize situations that activate biases:

**High-pressure sales environments**: Artificial scarcity, urgency
**Social settings**: Conformity pressure, social proof
**Luxury contexts**: Halo effect, anchoring
**Crisis situations**: Availability heuristic, fear-based compliance
**After investments (time, money, emotion)**: Sunk cost triggers

**Language Red Flags**

Certain phrases should trigger immediate suspicion:

- "Act now" / "Limited time" → Scarcity manipulation
- "Everyone is..." / "Most people..." → Bandwagon appeal
- "You don't want to lose..." → Loss aversion trigger
- "Originally priced at..." → Anchoring attempt
- "Trust me" / "Believe me" → Authority without evidence
- "You're smart enough to see..." → Flattery + commitment trap

**The Meta-Awareness Practice**

Develop the habit of stepping outside yourself during important decisions:

1. **Name the emotion**: "I'm feeling excited/anxious/pressured"
2. **Identify the trigger**: "This started when they mentioned..."
3. **Map to bias**: "This feels like scarcity/social proof/anchoring"
4. **Apply countermeasure**: "I need to step back and verify independently"

**Building Your Personal Alert System**

Different people are vulnerable to different biases. Through reflection, identify your personal vulnerabilities:

- Do you hate feeling left out? (Bandwagon, FOMO)
- Do you struggle to quit things? (Sunk cost)
- Are you particularly influenced by credentials? (Authority)
- Do you make decisions quickly when excited? (Halo, anchoring)

Once you know your patterns, you can set specific triggers: "When I feel [this way], I will [pause and do this]."

**The 24-Hour Rule**

For any significant decision made under emotional activation, implement a mandatory waiting period. Biases are strongest in the moment and fade with time. If the opportunity is real, it will still be there tomorrow.`,
      keyTakeaway: 'Your body and emotions signal when biases are being triggered. Learning to recognize these signals in real-time is your most practical defense.',
      actionItem: 'Create a personal "bias vulnerability profile." List your top 3 cognitive weaknesses and the emotional/physical signals that accompany them.',
    },
  },
  {
    id: 'dp-bias-013',
    title: 'Decision-Making Frameworks to Counter Biases',
    type: 'concept',
    duration: 15,
    xpReward: 140,
    content: {
      overview: 'Structured approaches that systematically reduce bias impact on important decisions.',
      mainContent: `**Systems Over Willpower**

You cannot think your way out of biases through sheer effort—they're hardwired. Instead, you need external systems that force better thinking. These frameworks create structure that counteracts bias automatically.

**Framework 1: The Pre-Mortem**

Before making a decision, imagine it's one year later and the decision failed catastrophically. Now work backward: What went wrong?

This technique:
- Counters **optimism bias** by forcing you to consider failure
- Surfaces concerns people might hesitate to voice
- Identifies risks that confirmation bias would hide
- Converts vague anxiety into specific, addressable concerns

**Framework 2: The 10-10-10 Rule**

Ask yourself:
- How will I feel about this decision in 10 minutes?
- How will I feel in 10 months?
- How will I feel in 10 years?

This technique:
- Counters **present bias** (overweighting immediate rewards)
- Reduces **emotional hijacking** by introducing temporal distance
- Reveals which concerns are fleeting vs. fundamental

**Framework 3: The Outsider Test**

Imagine advising a friend facing this exact situation. What would you tell them?

This technique:
- Counters **self-serving bias** by removing ego from the equation
- Reduces **sunk cost** influence (you wouldn't tell a friend to continue just because they'd already invested)
- Clarifies thinking by reducing emotional involvement

**Framework 4: The Steel Man Method**

Before rejecting an opposing view, construct the strongest possible version of that argument. Argue for it as persuasively as you can.

This technique:
- Counters **confirmation bias** by forcing genuine engagement with alternatives
- Prevents **straw manning** (attacking weak versions of opposing views)
- Often reveals legitimate concerns you'd otherwise dismiss

**Framework 5: Structured Decision Matrix**

For complex decisions:
1. List all options
2. Identify evaluation criteria (before looking at options in detail)
3. Weight the criteria by importance
4. Score each option on each criterion
5. Calculate weighted totals

This technique:
- Counters **anchoring** by establishing criteria before exposure to specifics
- Reduces **halo effect** by separating evaluation dimensions
- Creates accountability and traceability for decisions

**Framework 6: Red Team / Devil's Advocate**

Assign someone (or yourself, on a different day) to argue against your preferred option as vigorously as possible.

This technique:
- Counters **groupthink** and **bandwagon effect**
- Surfaces weaknesses that confirmation bias hides
- Tests whether your position can withstand serious challenge

**Implementation Key**

These frameworks only work if you use them BEFORE making the decision, not after. Once you've committed, biases will corrupt even structured analysis. Build the habit of reaching for frameworks early, when you first recognize an important decision is at hand.`,
      keyTakeaway: 'Structured decision frameworks create external systems that counteract biases automatically. Use them before deciding, not after.',
      actionItem: 'Choose one framework and apply it to a current decision you are facing. Document the process and notice what it reveals that intuition missed.',
    },
  },
  {
    id: 'dp-bias-014',
    title: 'Debiasing Techniques - Practical Methods',
    type: 'concept',
    duration: 14,
    xpReward: 140,
    content: {
      overview: 'Specific, actionable techniques to reduce the impact of cognitive biases in everyday situations.',
      mainContent: `**The Debiasing Toolkit**

While biases cannot be eliminated, their impact can be significantly reduced through deliberate techniques. Here are practical methods you can apply immediately.

**Technique 1: Consider the Opposite**

When you've reached a conclusion, deliberately ask: "What if the opposite were true? What evidence would support that?"

**Application**: Before finalizing any judgment about a person, situation, or decision, spend equal time arguing the contrary position.

**Effective against**: Confirmation bias, anchoring, halo/horns effect

**Technique 2: Make Predictions Explicit**

Write down your expectations before outcomes are known. This creates accountability and reveals calibration errors.

**Application**: Before a meeting, write what you expect to happen. Before an investment, write your expected return and timeline. Review these predictions regularly.

**Effective against**: Hindsight bias, overconfidence, selective memory

**Technique 3: Use Base Rates**

When estimating probability, start with the general frequency (base rate) before adjusting for specific circumstances.

**Application**: Instead of "Will this startup succeed?" ask "What percentage of startups in this sector succeed? What specific evidence suggests this one differs from the base rate?"

**Effective against**: Availability heuristic, representativeness bias, optimism bias

**Technique 4: Separate Information from Source**

Evaluate claims independently of who makes them. Write down the argument without attribution, then assess it.

**Application**: When reading an expert opinion, cover the author's credentials and ask: "Would I find this argument compelling if a random person made it?"

**Effective against**: Authority bias, halo effect, ad hominem reasoning

**Technique 5: Implement Waiting Periods**

Create mandatory delays before significant decisions, especially those made under emotional activation.

**Application**: 24 hours for purchases over $100. One week for major commitments. Sleep on anything that triggers strong emotions.

**Effective against**: Present bias, emotional hijacking, scarcity manipulation

**Technique 6: Seek Disconfirming Evidence**

Actively search for information that contradicts your current view. Make this a deliberate, regular practice.

**Application**: Before any important decision, spend dedicated time looking specifically for reasons NOT to do it. Treat this as a required step, not optional.

**Effective against**: Confirmation bias, overconfidence, groupthink

**Technique 7: Establish Reference Classes**

Group the current situation with similar past situations and examine outcomes across the class.

**Application**: "This investment opportunity" becomes "investments with similar characteristics." How did those perform? Your situation is probably not as unique as it feels.

**Effective against**: Optimism bias, uniqueness bias, planning fallacy

**The Compound Effect**

No single technique eliminates bias, but combining multiple techniques creates substantial protection. Build these methods into your routine so they become automatic, not effortful. The goal is to make better thinking your default, not your exception.`,
      keyTakeaway: 'Practical debiasing requires specific techniques applied consistently. Build these methods into routine habits for maximum protection.',
      actionItem: 'Select two techniques from this lesson. Commit to applying them for the next week in specific situations. Track when you use them and what you notice.',
    },
  },
  {
    id: 'dp-bias-015',
    title: 'Building Bias Awareness Habits',
    type: 'concept',
    duration: 15,
    xpReward: 150,
    content: {
      overview: 'Creating sustainable practices that maintain long-term cognitive defense against manipulation.',
      mainContent: `**From Knowledge to Habit**

Understanding biases intellectually provides limited protection. Manipulators exploit the gap between knowing and doing. This lesson focuses on converting knowledge into automatic habits that protect you consistently.

**The Habit Architecture**

Effective bias awareness requires:

1. **Cue**: A trigger that initiates the protective behavior
2. **Routine**: The specific action you take
3. **Reward**: Positive reinforcement that sustains the habit

**Daily Practices**

**Morning Intention Setting** (2 minutes)
- Cue: Part of morning routine
- Routine: Ask "What decisions might I face today? What biases might be relevant?"
- Reward: Feeling of preparedness and control

**Decision Journal** (5 minutes daily)
- Cue: Evening reflection time
- Routine: Record one decision made, the biases potentially at play, and how you handled them
- Reward: Pattern recognition over time, learning from experience

**The Pause Protocol** (Ongoing)
- Cue: Feeling of urgency, excitement, or pressure
- Routine: Stop. Breathe. Ask "What bias might be operating right now?"
- Reward: Avoided manipulation, maintained autonomy

**Weekly Practices**

**Information Diet Review** (15 minutes)
- Examine your information sources for the week
- Ask: Am I in an echo chamber? Did I encounter genuinely challenging ideas?
- Diversify sources deliberately if needed

**Decision Retrospective** (20 minutes)
- Review significant decisions from the past week
- What influenced you? Were biases involved? What would you do differently?
- Update your personal bias vulnerability profile

**Monthly Practices**

**Belief Audit** (30 minutes)
- Select one strong belief you hold
- Actively research opposing views
- Ask: Is this belief evidence-based or identity-based?

**Manipulation Log Review**
- Review attempted manipulations you've noticed
- What techniques were used? How did you respond?
- What patterns are you seeing?

**Environmental Design**

Structure your environment to support good decisions:

- **Remove friction** from good choices (decision frameworks easily accessible)
- **Add friction** to impulsive choices (waiting periods, approval requirements)
- **Build in accountability** (trusted advisor to consult on major decisions)
- **Limit exposure** to manipulative environments when possible

**The Maintenance Mindset**

Bias awareness is not a skill you master once—it's a practice you maintain. Manipulators evolve their techniques. Your defenses must evolve too.

Key maintenance principles:
- **Humility**: You will still be fooled sometimes. Learn from it without shame
- **Curiosity**: Stay interested in how influence works, including on yourself
- **Practice**: Regular application strengthens these mental muscles
- **Community**: Surround yourself with others who value clear thinking

**The Long Game**

Each small instance of catching a bias, pausing before a decision, or recognizing manipulation strengthens your cognitive immune system. These micro-practices compound over time into significant protection. The manipulator's greatest advantage is your autopilot—disrupt that autopilot, and you've shifted the balance of power.`,
      keyTakeaway: 'Bias awareness must become habitual to be effective. Build systematic practices into your daily, weekly, and monthly routines.',
      actionItem: 'Design your personal bias awareness system. Choose one daily, one weekly, and one monthly practice. Schedule them now and commit to 30 days of implementation.',
    },
  },
];
